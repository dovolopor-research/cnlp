<div align="center">
  <img src="https://ailln.oss-cn-hangzhou.aliyuncs.com/github/cnlp/cnlp-logo-v4.png" width="60%">
  <br>
  <img src="https://img.shields.io/pypi/v/cnlp.svg">
  <img src="https://img.shields.io/badge/license-MIT-green.svg">
  <img src="https://img.shields.io/github/stars/dovolopor-research/cnlp.svg">
</div>

# cnlp = cn + nlp

ğŸ”¥ ä¸“æ³¨äºä¸­æ–‡çš„ã€Œè‡ªç„¶è¯­è¨€å¤„ç†æ¡†æ¶ã€

## 1 åŠŸèƒ½

1. [cnlp.data](https://cnlp.dovolopor.com/api/#_1-cnlp-data): ä¸€ä¸ªé€šç”¨çš„æ–‡æœ¬å¤„ç†å™¨ã€‚
2. [cnlp.dataset](https://cnlp.dovolopor.com/api/#_2-cnlp-dataset): æä¾›å¸¸è§çš„æ•°æ®é›†åŠ è½½ã€‚
3. [cnlp.model](https://cnlp.dovolopor.com/api/#_3-cnlp-model): æä¾›å¸¸è§çš„æ¨¡å‹ã€‚

## 2 å®‰è£…

### 2.1 pip å®‰è£…

```bash
pip install cnlp
```

### 2.2 æ‰‹åŠ¨å®‰è£…

```bash
git clone https://github.com/dovolopor-research/cnlp.git
cd cnlp && python setup.py install
```

## 3 å¿«é€Ÿä¸Šæ‰‹

### ä¸­æ–‡åˆ†è¯

åˆ†è¯æ˜¯ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†æœ€åŸºç¡€çš„ä»»åŠ¡ä¹‹ä¸€ï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹ä¸ªåˆ†è¯çš„ä¾‹å­ã€‚

```python
from cnlp.data import Tokenizer

t = Tokenizer()

# é»˜è®¤æ–¹å¼ä¸ºæœ‰å‘æ— ç¯å›¾åˆ†è¯
result = t.cut("ä¸ºä¸­åä¹‹å´›èµ·è€Œè¯»ä¹¦")
# result:
# ['ä¸º', 'ä¸­å', 'ä¹‹', 'å´›èµ·', 'è€Œ', 'è¯»ä¹¦']

# æœºæ¢°åˆ†è¯
result = t.cut("ä¸ºä¸­åä¹‹å´›èµ·è€Œè¯»ä¹¦", methods="mechanical")
# result:
# ['ä¸º', 'ä¸­å', 'ä¹‹', 'å´›èµ·', 'è€Œ', 'è¯»ä¹¦']

# è·å–åæ—
result = t.radical("ä¸ºä¸­åä¹‹å´›èµ·è€Œè¯»ä¹¦")
# result:
# ['ä¸¶', 'ä¸¨', 'å', 'ä¸¶', '@UNK@', 'èµ°', 'è€Œ', 'è® ', 'ä¹›']

# è·å–éƒ¨é¦–
result = t.stroke("ä¸ºä¸­åä¹‹å´›èµ·è€Œè¯»ä¹¦")
# result:
# [['ç‚¹', 'æ’‡', 'æ¨ªæŠ˜ç«–é’©', 'ç‚¹'], ['ç«–', 'æ¨ªæŠ˜', 'æ¨ª', 'ç«–'], ['æ’‡', 'ç«–', 'æ’‡', 'ç«–å¼¯æ¨ªé’©', 'æ¨ª', 'ç«–'],
# ['ç‚¹', 'æ¨ªæ’‡', 'æº'], '@UNK@', ['æ¨ª', 'ç«–', 'æ¨ª', 'ç«–', 'æ¨ª', 'æ’‡', 'æ’‡', 'ç«–', 'æ¨ªæŠ˜ç«–é’©', 'ç«–', 'ç«–'],
# ['ç‚¹', 'æ¨ªæŠ˜æ', 'æ¨ª', 'ç«–', 'æ¨ªæ’‡', 'ç‚¹', 'ç‚¹', 'æ¨ª', 'æ’‡', 'ç‚¹'], ['æ¨ªæŠ˜', 'æ¨ªæŠ˜ç«–é’©', 'ç«–', 'ç‚¹']]
```

### ç±»åˆ«ä¸å¹³è¡¡

æ•°æ®é›†ä¸­çš„ç±»åˆ«ä¸å¹³è¡¡æ˜¯åœ¨å®é™…æ•°æ®é›†ä¸­ç»å¸¸é‡åˆ°çš„é—®é¢˜ï¼Œé€šå¸¸é‡‡ç”¨**è¿‡é‡‡æ ·æ‰©å……**æˆ–è€…**æ¬ é‡‡æ ·ç¼©å‡**çš„æ–¹å¼è§£å†³ã€‚

```python
from cnlp.data import sampling

# ç±»åˆ« pos:3 neg:2 unk:1
origin_dataset = [
  ["æˆ‘å¥½å¼€å¿ƒï¼", "pos"],
  ["ä»Šå¤©å¿ƒæƒ…ä¸é”™å•Šï½", "pos"],
  ["å­¦ä¼šäº† cnlpï¼ŒçœŸæ£’ï¼", "pos"],
  ["æˆ‘å¿ƒæ€å´©äº†å•Šï¼", "neg"],
  ["å“ï¼ŒåˆåŠ ç­ã€‚ã€‚ã€‚", "neg"],
  ["åƒé›ªç³•ä¸­", "unk"]
]

# é»˜è®¤ä¸ºè¿‡é‡‡æ ·ï¼Œéƒ½æ‰©å……åˆ° 3
dataset = sampling(origin_dataset)
# dataset:
# [
#   ["æˆ‘å¥½å¼€å¿ƒï¼", "pos"],
#   ["ä»Šå¤©å¿ƒæƒ…ä¸é”™å•Šï½", "pos"],
#   ["å­¦ä¼šäº† cnlpï¼ŒçœŸæ£’ï¼", "pos"],
#   ["æˆ‘å¿ƒæ€å´©äº†å•Šï¼", "neg"],
#   ["å“ï¼ŒåˆåŠ ç­ã€‚ã€‚ã€‚", "neg"],
#   ["æˆ‘å¿ƒæ€å´©äº†å•Šï¼", "neg"],
#   ["åƒé›ªç³•ä¸­", "unk"],
#   ["åƒé›ªç³•ä¸­", "unk"],
#   ["åƒé›ªç³•ä¸­", "unk"]
# ]

# ä¹Ÿå¯ä»¥ä½¿ç”¨æ¬ é‡‡æ ·ï¼Œéƒ½ç¼©å‡åˆ°1
# è¿™ç§æ–¹å¼ä¸æ¨èï¼Œå®¹æ˜“ä½¿æ¨¡å‹è¿‡æ‹Ÿåˆ
dataset = sampling(origin_dataset, mode="under")
# dataset:
# [
#   ["å­¦ä¼šäº† cnlpï¼ŒçœŸæ£’ï¼", "pos"],
#   ["æˆ‘å¿ƒæ€å´©äº†å•Šï¼", "neg"],
#   ["åƒé›ªç³•ä¸­", "unk"]
# ]
```

### æ•°æ®é›†åˆ’åˆ†

æ•°æ®é›†åˆ’åˆ†æ˜¯è®­ç»ƒæ¨¡å‹å‰çš„å¸¸è§æ“ä½œï¼Œè¿™é‡Œä¹Ÿæä¾›äº†ä¸€ä¸ªåŸºæœ¬çš„æ–¹æ³•ã€‚

```python
from cnlp.data import split

origin_dataset = [
  "ä»Šå¤©å¤©æ°”ä¸é”™å•Š",
  "æˆ‘æƒ³åƒçƒ§çƒ¤",
  "åœ°çƒäººå°±çŸ¥é“åƒ",
  "è¯´çš„å¥½åƒä½ ä»¬ç«æ˜Ÿäººä¸çˆ±åƒä¸€æ ·",
  "æ²¡é”™å•Šï¼",
  "å¥½å§",
  "ä½ èµ¢äº†",
  "é‚£è¯·ä½ ç¦»å¼€åœ°çƒ",
  "å¿«èµ°",
  "å¿«å¿«èµ°"
]

# é»˜è®¤ä»¥ train:test = 7:3 åˆ’åˆ†
train_data, test_data = split(origin_dataset)
# train_data:
# ['ä»Šå¤©å¤©æ°”ä¸é”™å•Š', 'æˆ‘æƒ³åƒçƒ§çƒ¤', 'åœ°çƒäººå°±çŸ¥é“åƒ', 'è¯´çš„å¥½åƒä½ ä»¬ç«æ˜Ÿäººä¸çˆ±åƒä¸€æ ·', 'æ²¡é”™å•Šï¼', 'å¥½å§', 'ä½ èµ¢äº†']
# test_data:
# ['é‚£è¯·ä½ ç¦»å¼€åœ°çƒ', 'å¿«èµ°', 'å¿«å¿«èµ°']

# æ”¯æŒåˆ’åˆ† train val test ä¸‰ç§æ•°æ®é›†
train_data, val_data, test_data = split(origin_dataset, [0.5, 0.3, 0.2])
# train_data:
# ['ä»Šå¤©å¤©æ°”ä¸é”™å•Š', 'æˆ‘æƒ³åƒçƒ§çƒ¤', 'åœ°çƒäººå°±çŸ¥é“åƒ', 'è¯´çš„å¥½åƒä½ ä»¬ç«æ˜Ÿäººä¸çˆ±åƒä¸€æ ·', 'æ²¡é”™å•Šï¼'],
# val_data:
# ['å¥½å§', 'ä½ èµ¢äº†', 'é‚£è¯·ä½ ç¦»å¼€åœ°çƒ']
# test_data:
# ['å¿«èµ°', 'å¿«å¿«èµ°']

# æ”¯æŒæ‰“ä¹±(shuffle)
train_data, val_data, test_data = split(origin_dataset, [0.5, 0.3, 0.2], shuffle=True)
# train_data:
# ['ä½ èµ¢äº†', 'è¯´çš„å¥½åƒä½ ä»¬ç«æ˜Ÿäººä¸çˆ±åƒä¸€æ ·', 'å¿«èµ°', 'ä»Šå¤©å¤©æ°”ä¸é”™å•Š', 'é‚£è¯·ä½ ç¦»å¼€åœ°çƒ']
# val_data:
# ['æˆ‘æƒ³åƒçƒ§çƒ¤', 'å¿«å¿«èµ°', 'åœ°çƒäººå°±çŸ¥é“åƒ']
# test_data:
# ['æ²¡é”™å•Šï¼', 'å¥½å§']
```

## 4 æ–‡æ¡£

è¯·åœ¨ [https://cnlp.dovolopor.com](https://cnlp.dovolopor.com) ä¸­æŸ¥çœ‹å®ƒã€‚

## 5 è´¡çŒ®

å¦‚æœæ‚¨è®¡åˆ’ä¸ºæ­¤é¡¹ç›®æä¾›æ–°åŠŸèƒ½ï¼Œå®ç”¨ç¨‹åºåŠŸèƒ½æˆ–æ‰©å±•ï¼Œè¯·é¦–å…ˆæ‰“å¼€ä¸€ä¸ª [Issues](https://github.com/dovolopor-research/cnlp/issues) å¹¶ä¸æˆ‘ä»¬è®¨è®ºè¯¥åŠŸèƒ½ã€‚

## 6 è®¸å¯è¯

[![](https://award.dovolopor.com?lt=License&rt=MIT&rbc=green)](./LICENSE)

## 7 äº¤æµ

æ¬¢è¿æ·»åŠ å¾®ä¿¡å·ï¼š`Ailln_`ï¼Œå¤‡æ³¨ã€Œcnlpã€ï¼Œæˆ‘é‚€è¯·ä½ è¿›å…¥äº¤æµç¾¤ã€‚

## 8 å‚è€ƒ

- [jieba åˆ†è¯](https://github.com/fxsjy/jieba)
- [Torch Text](https://github.com/pytorch/text)